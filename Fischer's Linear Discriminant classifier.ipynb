{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "colab": {
   "name": "Assignment_1.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "\n",
     "\n",
     "\n",
     "\n",
     "\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ONLY USE THESE IMPORTS.\n",
    "# PLEASE DON'T EDIT THIS CELL.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MSAl9o2bTz4"
   },
   "source": [
    "## Read Data (Edit)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "M98Jv7ACbTz5"
   },
   "source": [
    "x_train_frog = np.array([plt.imread('Data/train/frog/' + str(i) + '.jpg').reshape(-1) for i in range(0, 5000)])\n",
    "x_train_frog_temp = x_train_frog\n",
    "x_train_airplane = np.array([plt.imread('Data/train/airplane/' + str(i) + '.jpg').reshape(-1) for i in range(0, 5000)])\n",
    "x_train_airplane_temp = x_train_airplane\n",
    "x_train_automobile = np.array(\n",
    "    [plt.imread('Data/train/automobile/' + str(i) + '.jpg').reshape(-1) for i in range(0, 5000)])\n",
    "\n",
    "x_train_automobile_temp = x_train_automobile\n",
    "x_test_frog = np.array([plt.imread('Data/test/frog/' + str(i) + '.jpg').reshape(-1) for i in range(0, 1000)])\n",
    "x_test_frog_temp = x_test_frog\n",
    "x_test_airplane = np.array([plt.imread('Data/Test/airplane/' + str(i) + '.jpg').reshape(-1) for i in range(0, 1000)])\n",
    "x_test_airplane_temp = x_test_airplane\n",
    "x_test_automobile = np.array(\n",
    "    [plt.imread('Data/test/automobile/' + str(i) + '.jpg').reshape(-1) for i in range(0, 1000)])\n",
    "x_test_automobile_temp = x_test_automobile\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRsd4OUlbTz6"
   },
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>\n",
    "\n",
    "## Construct Fischer's Linear Discriminant classifier for each of the 3 classes.\n",
    "#### Test each classifier on all images in X_Test. \n",
    "#### Construct Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4TEXrY-TbTz6"
   },
   "source": [
    "def normalize(array):\n",
    "    array = np.divide(array, 255)\n",
    "    return array\n",
    "\n",
    "\n",
    "x_train_frog = normalize(x_train_frog)\n",
    "x_train_automobile = normalize(x_train_automobile)\n",
    "x_train_airplane = normalize(x_train_airplane)\n",
    "x_test_frog = normalize(x_test_frog)\n",
    "x_test_automobile = normalize(x_test_automobile)\n",
    "x_test_airplane = normalize(x_test_airplane)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2lbYxQ0qFzeZ"
   },
   "source": [
    "def reshape(x_train_frog, x_train_automobile, x_train_airplane):\n",
    "    x_train = x_train_airplane\n",
    "    x_train = np.concatenate((x_train, x_train_frog))\n",
    "    x_train = np.concatenate((x_train, x_train_automobile))\n",
    "    return (x_train)\n",
    "\n",
    "\n",
    "x_train = reshape(x_train_frog, x_train_automobile, x_train_airplane)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Tu8kHSq8Fzpi"
   },
   "source": [
    "def classifier(array, value1, value2, value3):\n",
    "    mean = []\n",
    "    mean_not_a = []\n",
    "    x = []\n",
    "    for i in range(0, value3):\n",
    "        a = array[value1:value2, i]\n",
    "        mean.append(np.mean(a))\n",
    "    for i in range(0, value3):\n",
    "        x.append(np.subtract(array[value1:value2, i], mean[i]))\n",
    "    transpose = np.transpose(np.matrix(x))\n",
    "    sw_a = np.matmul(x, transpose)\n",
    "    if value1 == 0 and value2 == 5000:\n",
    "        x = []\n",
    "        for i in range(0, value3):\n",
    "            a = array[value2:15000, i]\n",
    "            mean_not_a.append(np.mean(a))\n",
    "        for i in range(0, value3):\n",
    "            x.append(np.subtract(array[value2:15000, i], mean_not_a[i]))\n",
    "        transpose = np.transpose(np.matrix(x))\n",
    "        sw_not_a = np.matmul(x, transpose)\n",
    "    elif value1 == 5000 and value2 == 10000:\n",
    "        x = []\n",
    "        array = np.concatenate((array[0:5000, :], array[10000:15000, :]))\n",
    "        for i in range(0, value3):\n",
    "            a = array[:, i]\n",
    "            mean_not_a.append(np.mean(a))\n",
    "        for i in range(0, value3):\n",
    "            x.append(np.subtract(array[:, i], mean_not_a[i]))\n",
    "        transpose = np.transpose(np.matrix(x))\n",
    "        sw_not_a = np.matmul(x, transpose)\n",
    "    else:\n",
    "        x = []\n",
    "        for i in range(0, value3):\n",
    "            a = array[0:10000, i]\n",
    "            mean_not_a.append(np.mean(a))\n",
    "        for i in range(0, value3):\n",
    "            x.append(np.subtract(array[0:10000, i], mean_not_a[i]))\n",
    "        transpose = np.transpose(np.matrix(x))\n",
    "        sw_not_a = np.matmul(x, transpose)\n",
    "\n",
    "    sw = np.add(sw_a, sw_not_a)\n",
    "    sw_1 = np.linalg.pinv(sw)\n",
    "    mean_difference = np.subtract(mean, mean_not_a)\n",
    "    mean_difference = mean_difference[:, None]\n",
    "    classify = np.matmul(sw_1, mean_difference)\n",
    "    mean_addition = np.add(mean, mean_not_a)\n",
    "    mean_addition_m = np.multiply(mean_addition, (-0.5))\n",
    "    mean_addition_m = mean_addition_m[:, None]\n",
    "    scalar = np.matmul(np.transpose(classify), mean_addition_m)\n",
    "    return scalar[0][0], classify\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "J0acgIdgF9Cm"
   },
   "source": [
    "airplane_w0, airplane_classifier = classifier(x_train, 0, 5000, 3072)\n",
    "frog_w0, frog_classifier = classifier(x_train, 5000, 10000, 3072)\n",
    "automobile_w0, automobile_classifier = classifier(x_train, 10000, 15000, 3072)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AoPampLDcjf2"
   },
   "source": [
    "def predict(x_test_auto, x_test_air, x_test_f, w0, w1, w2, airclass, autoclass, frogclass):\n",
    "    y_test_airplane = []\n",
    "    y_test_automobile = []\n",
    "    y_test_frog = []\n",
    "    countairf = 0\n",
    "    countair = 0\n",
    "    countairauto = 0\n",
    "    cm = []\n",
    "    for i in range(len(x_test_air)):\n",
    "        y_test_airplane.append(np.dot(x_test_air[i], airclass) + w0)\n",
    "        y_test_automobile.append(np.dot(x_test_auto[i], airclass) + w0)\n",
    "        y_test_frog.append(np.dot(x_test_f[i], airclass) + w0)\n",
    "        predicted = max(y_test_airplane[i], y_test_automobile[i], y_test_frog[i])\n",
    "        if (predicted[0] == y_test_airplane[i]):\n",
    "            countair += 1\n",
    "        elif (predicted[0] == y_test_automobile[i]):\n",
    "            countairauto += 1\n",
    "        else:\n",
    "            countairf += 1\n",
    "    countfrog = 0\n",
    "    countfrogauto = 0\n",
    "    countfrogair = 0\n",
    "    print(countair, countairf, countairauto)\n",
    "    y_test_airplane = []\n",
    "    y_test_automobile = []\n",
    "    y_test_frog = []\n",
    "    for i in range(len(x_test_f)):\n",
    "        y_test_airplane.append(np.dot(x_test_air[i], frogclass) + w1)\n",
    "        y_test_automobile.append(np.dot(x_test_auto[i], frogclass) + w1)\n",
    "        y_test_frog.append(np.dot(x_test_f[i], frogclass) + w1)\n",
    "        predicted = max(y_test_airplane[i], y_test_automobile[i], y_test_frog[i])\n",
    "        if predicted[0] == y_test_airplane[i]:\n",
    "            countfrogair += 1\n",
    "        elif predicted[0] == y_test_automobile[i]:\n",
    "            countfrogauto += 1\n",
    "        else:\n",
    "            countfrog += 1\n",
    "    print([countfrog, countfrogauto, countfrogair])\n",
    "    countauto = 0\n",
    "    countautof = 0\n",
    "    countautoair = 0\n",
    "    y_test_airplane = []\n",
    "    y_test_automobile = []\n",
    "    y_test_frog = []\n",
    "    for i in range(len(x_test_auto)):\n",
    "        y_test_airplane.append(np.dot(x_test_air[i], autoclass) + w2)\n",
    "        y_test_automobile.append(np.dot(x_test_auto[i], autoclass) + w2)\n",
    "        y_test_frog.append(np.dot(x_test_f[i], autoclass) + w2)\n",
    "        predicted = max(y_test_airplane[i], y_test_automobile[i], y_test_frog[i])\n",
    "        if (predicted[0] == y_test_airplane[i]):\n",
    "            countautoair += 1\n",
    "        elif (predicted[0] == y_test_automobile[i]):\n",
    "            countauto += 1\n",
    "        else:\n",
    "            countautof += 1\n",
    "    print(countauto, countautof, countautoair)\n",
    "    cm = [[countair, countairf, countairauto], [countfrogair, countfrog, countfrogauto],\n",
    "          [countautoair, countautof, countauto]]\n",
    "    airpredict = max(countair, countairf, countairauto)\n",
    "    frogpredict = max(countfrog, countfrogauto, countfrogair)\n",
    "    autopredict = max(countauto, countautoair, countautof)\n",
    "    return cm"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MKc-q2mbTz6"
   },
   "source": [
    "## Confusion Matrix (Don't Edit)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g6dI0y5jbTz7"
   },
   "source": [
    "cm = predict(x_test_automobile, x_test_airplane, x_test_frog, airplane_w0, frog_w0, automobile_w0, airplane_classifier,\n",
    "             automobile_classifier, frog_classifier)\n",
    "\n",
    "# Test\n",
    "\n",
    "\n",
    "confusion_matrix = np.array(cm)\n",
    "\n",
    "accuracy = np.diag(confusion_matrix).sum() / 3000\n",
    "plt.rc('figure', figsize=[5, 5])\n",
    "plt.matshow(confusion_matrix, cmap=\"Blues\")\n",
    "plt.title('FLD+RGB = {0:0.3f}'.format(accuracy))\n",
    "for i in range(0, confusion_matrix.shape[0]):\n",
    "    for j in range(0, confusion_matrix.shape[1]):\n",
    "        plt.annotate(confusion_matrix[i, j], (j, i))\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "falaP6EtbTz7"
   },
   "source": [
    "### Repeat for Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WdZbcLy-cxfT"
   },
   "source": [
    "def togray(image):\n",
    "    count = 0\n",
    "    im = []\n",
    "    while count + 3 <= len(image[0]):\n",
    "        r, g, b = image[:, count], image[:, count + 1], image[:, count + 2]\n",
    "        r = np.multiply(r, 0.2989)\n",
    "        g = np.multiply(g, 0.5870)\n",
    "        b = np.multiply(b, 0.1140)\n",
    "        np.add(r, g, b)\n",
    "        im.append(np.add(r, g, b))\n",
    "        count = count + 3\n",
    "    im = np.transpose(im)\n",
    "    return im"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sd61dLqCbTz7"
   },
   "source": [
    "x_train_frog_grayscale = normalize(x_train_frog_temp)\n",
    "x_train_frog_grayscale = togray(x_train_frog_grayscale)\n",
    "\n",
    "x_train_automobile_grayscale = normalize(x_train_automobile_temp)\n",
    "x_train_automobile_grayscale = togray(x_train_automobile_grayscale)\n",
    "\n",
    "x_train_airplane_grayscale = normalize(x_train_airplane_temp)\n",
    "x_train_airplane_grayscale = togray(x_train_airplane_grayscale)\n",
    "\n",
    "x_train_grayscale = reshape(x_train_frog_grayscale, x_train_automobile_grayscale, x_train_airplane_grayscale)\n",
    "\n",
    "airplanew0grey, airplane_grayscale = classifier(x_train_grayscale, 0, 5000, 1024)\n",
    "frogw0grery, frog_grayscale = classifier(x_train_grayscale, 5000, 10000, 1024)\n",
    "autow0grey, automobile_grayscale = classifier(x_train_grayscale, 10000, 15000, 1024)\n",
    "\n",
    "\n",
    "x_test_auto_grayscale = normalize(x_test_automobile_temp)\n",
    "x_test_auto_grayscale = togray(x_test_auto_grayscale)\n",
    "x_test_airplane_grayscale = normalize(x_test_airplane_temp)\n",
    "x_test_airplane_grayscale = togray(x_test_airplane_grayscale)\n",
    "x_test_frog_grayscale = normalize(x_test_frog_temp)\n",
    "x_test_frog_grayscale = togray(x_test_frog_grayscale)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cp9G-rHRbTz8"
   },
   "source": [
    "## Confusion Matrix (Don't Edit)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nquEw9eQbTz8"
   },
   "source": [
    "cm = predict(x_test_auto_grayscale, x_test_airplane_grayscale, x_test_frog_grayscale, airplanew0grey, frogw0grery,\n",
    "             autow0grey, airplane_grayscale, automobile_grayscale, frog_grayscale)\n",
    "\n",
    "confusion_matrix = np.array(cm)\n",
    "\n",
    "\n",
    "accuracy = np.diag(confusion_matrix).sum() / 3000\n",
    "plt.rc('figure', figsize=[5, 5])\n",
    "plt.matshow(confusion_matrix, cmap=\"Blues\")\n",
    "plt.title('FLD+GRAY = {0:0.3f}'.format(accuracy))\n",
    "for i in range(0, confusion_matrix.shape[0]):\n",
    "    for j in range(0, confusion_matrix.shape[1]):\n",
    "        plt.annotate(confusion_matrix[i, j], (j, i))\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CC-TkFt4bTz9"
   },
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>\n",
    "\n",
    "## Comment on the change of accuracy between RGB and Grayscale\n",
    "##########\n",
    "\n",
    "\n",
    "The comments are in the report\n",
    "uploaded (ml.docx)\n",
    "We uploaded two other files (main.py) and this colab file , main.py is our original python file as we worked on pycharm as  the upload of files would take long time with colab and we copied the .py file in this .ipnyb file we uploaded both \n",
    "thank you,\n",
    "...\n",
    "...\n",
    "\n",
    "##########\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  }
 ]
}